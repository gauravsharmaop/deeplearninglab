{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11133476,"sourceType":"datasetVersion","datasetId":6943859},{"sourceId":11144539,"sourceType":"datasetVersion","datasetId":6952114}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom collections import defaultdict\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:22:10.290655Z","iopub.execute_input":"2025-03-25T05:22:10.290873Z","iopub.status.idle":"2025-03-25T05:22:15.314642Z","shell.execute_reply.started":"2025-03-25T05:22:10.290851Z","shell.execute_reply":"2025-03-25T05:22:15.313671Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:23:14.183733Z","iopub.execute_input":"2025-03-25T05:23:14.184041Z","iopub.status.idle":"2025-03-25T05:23:14.261743Z","shell.execute_reply.started":"2025-03-25T05:23:14.184019Z","shell.execute_reply":"2025-03-25T05:23:14.260575Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load dataset from CSV\ndef load_data(csv_path):\n    df = pd.read_csv(csv_path)\n    text = ' '.join(df['text'].tolist())  # Assuming 'poem' column has text\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:23:45.309931Z","iopub.execute_input":"2025-03-25T05:23:45.310232Z","iopub.status.idle":"2025-03-25T05:23:45.314202Z","shell.execute_reply.started":"2025-03-25T05:23:45.310211Z","shell.execute_reply":"2025-03-25T05:23:45.313216Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Tokenization and vocabulary creation\ndef tokenize(text):\n    words = text.split()\n    vocab = sorted(set(words))\n    word_to_idx = {word: i for i, word in enumerate(vocab)}\n    idx_to_word = {i: word for word, i in word_to_idx.items()}\n    return words, vocab, word_to_idx, idx_to_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:23:59.776485Z","iopub.execute_input":"2025-03-25T05:23:59.776800Z","iopub.status.idle":"2025-03-25T05:23:59.781094Z","shell.execute_reply.started":"2025-03-25T05:23:59.776774Z","shell.execute_reply":"2025-03-25T05:23:59.780300Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Convert words to one-hot encoding\ndef one_hot_encode(words, vocab_size, word_to_idx):\n    encoded = np.zeros((len(words), vocab_size), dtype=np.float32)\n    for i, word in enumerate(words):\n        encoded[i, word_to_idx[word]] = 1.0\n    return encoded\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:24:48.748621Z","iopub.execute_input":"2025-03-25T05:24:48.748918Z","iopub.status.idle":"2025-03-25T05:24:48.753078Z","shell.execute_reply.started":"2025-03-25T05:24:48.748895Z","shell.execute_reply":"2025-03-25T05:24:48.752220Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# encoded = one_hot_encode(words,len(vocab),word_to_idx)\n\n# print(encoded[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T06:02:08.303792Z","iopub.execute_input":"2025-03-24T06:02:08.304149Z","iopub.status.idle":"2025-03-24T06:02:08.307970Z","shell.execute_reply.started":"2025-03-24T06:02:08.304072Z","shell.execute_reply":"2025-03-24T06:02:08.306917Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n# Define PyTorch Dataset class\nclass TextDataset(Dataset):\n    def __init__(self, encoded_words, seq_length):\n        self.inputs = np.array([encoded_words[i:i+seq_length] for i in range(len(encoded_words) - seq_length)])\n        self.targets = np.array([np.argmax(encoded_words[i+seq_length]) for i in range(len(encoded_words) - seq_length)])  # Convert to class indices\n        self.inputs = torch.tensor(self.inputs, dtype=torch.float32)\n        self.targets = torch.tensor(self.targets, dtype=torch.long)  # Ensure LongTensor for CrossEntropyLoss\n    \n    def __len__(self):\n        return len(self.inputs)\n    \n    def __getitem__(self, idx):\n        return self.inputs[idx], self.targets[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:29:10.995003Z","iopub.execute_input":"2025-03-25T05:29:10.995390Z","iopub.status.idle":"2025-03-25T05:29:11.001165Z","shell.execute_reply.started":"2025-03-25T05:29:10.995358Z","shell.execute_reply":"2025-03-25T05:29:11.000312Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Define LSTM model with One-Hot Encoding\nclass LSTMLanguageModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.3):\n        super(LSTMLanguageModel, self).__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        out, _ = self.lstm(x)\n        out = self.dropout(out[:, -1, :])\n        out = self.fc(out)  # No softmax; CrossEntropyLoss applies it internally\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:25:21.494219Z","iopub.execute_input":"2025-03-25T05:25:21.494549Z","iopub.status.idle":"2025-03-25T05:25:21.499511Z","shell.execute_reply.started":"2025-03-25T05:25:21.494523Z","shell.execute_reply":"2025-03-25T05:25:21.498583Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Training loop\ndef train_model(model, train_loader, criterion, optimizer, epochs=50):\n    model.to(device)  # Move model to GPU\n    for epoch in range(epochs):\n        total_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n        for inputs, targets in progress_bar:\n            inputs = inputs.to(device).float()  # Ensure FloatTensor for LSTM\n            targets = targets.to(device).long()  # Ensure LongTensor for CrossEntropyLoss\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            progress_bar.set_postfix(loss=total_loss/len(train_loader))\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:30:27.068856Z","iopub.execute_input":"2025-03-25T05:30:27.069218Z","iopub.status.idle":"2025-03-25T05:30:27.075014Z","shell.execute_reply.started":"2025-03-25T05:30:27.069191Z","shell.execute_reply":"2025-03-25T05:30:27.074009Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Test loop for accuracy\ndef test_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs = inputs.to(device).float()  # Ensure FloatTensor for LSTM\n            targets = targets.to(device).long()  # Ensure LongTensor for accuracy calculation\n            outputs = model(inputs)\n            predicted = torch.argmax(outputs, dim=1)\n            correct += (predicted == targets).sum().item()\n            total += targets.size(0)\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:30:30.080598Z","iopub.execute_input":"2025-03-25T05:30:30.080887Z","iopub.status.idle":"2025-03-25T05:30:30.086233Z","shell.execute_reply.started":"2025-03-25T05:30:30.080865Z","shell.execute_reply":"2025-03-25T05:30:30.085326Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:26:16.511467Z","iopub.execute_input":"2025-03-25T05:26:16.511757Z","iopub.status.idle":"2025-03-25T05:26:16.516333Z","shell.execute_reply.started":"2025-03-25T05:26:16.511736Z","shell.execute_reply":"2025-03-25T05:26:16.515658Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Main execution\ncsv_path = \"/kaggle/input/100poem/poems.csv\"  # Change this to your actual CSV file path\ntext = load_data(csv_path)\nwords, vocab, word_to_idx, idx_to_word = tokenize(text)\nencoded_words = one_hot_encode(words, len(vocab), word_to_idx)\n\nseq_length = 10  # Adjusted sequence length for better training\nbatch_size = 32  # Increased batch size to fully utilize T4 GPU\n\ndataset = TextDataset(encoded_words, seq_length)\ntrain_size = int(0.9 * len(dataset))  # Increased training split\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\ndataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\ndataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:30:36.343488Z","iopub.execute_input":"2025-03-25T05:30:36.343774Z","iopub.status.idle":"2025-03-25T05:30:41.314537Z","shell.execute_reply.started":"2025-03-25T05:30:36.343754Z","shell.execute_reply":"2025-03-25T05:30:41.313620Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"input_size = len(vocab)\nhidden_size = 256  # Increased hidden size for better learning\noutput_size = len(vocab)\n\ndropout_rate = 0.3  # Dropout to reduce overfitting\nmodel = LSTMLanguageModel(input_size, hidden_size, output_size, dropout_rate).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)  # Added L2 regularization\n\ntrain_model(model, dataloader_train, criterion, optimizer)\n\ntest_model(model, dataloader_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:30:45.264623Z","iopub.execute_input":"2025-03-25T05:30:45.264905Z","iopub.status.idle":"2025-03-25T05:34:49.127732Z","shell.execute_reply.started":"2025-03-25T05:30:45.264884Z","shell.execute_reply":"2025-03-25T05:34:49.126452Z"}},"outputs":[{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 7.464825186921262\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 7.054550866971071\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 6.924604674180348\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 6.75347157456409\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 6.496244740897212\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 6.166610841778503\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 5.787975005719853\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 5.346546948983751\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 4.833680253604363\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 4.287534544865291\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11, Loss: 3.7380456595585265\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12, Loss: 3.2006163602245263\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13, Loss: 2.6661528259858316\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14, Loss: 2.1883906338406707\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15, Loss: 1.74339821335228\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16, Loss: 1.3714973129246426\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17, Loss: 1.0713105546845787\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18, Loss: 0.8234375852277909\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19, Loss: 0.6388864118563032\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20, Loss: 0.5169267618022431\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21, Loss: 0.41804694375772583\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22, Loss: 0.3431486703840823\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23, Loss: 0.28381360316884585\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24, Loss: 0.2441704174953288\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25, Loss: 0.22173176925286822\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26, Loss: 0.19028067785775524\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27, Loss: 0.17012512620709752\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28, Loss: 0.15259110590378785\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29, Loss: 0.1435304281258977\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30, Loss: 0.1297616028526648\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-854f86d74e33>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Added L2 regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-b0c843ccbe1c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"test_model(model, dataloader_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T05:35:10.067994Z","iopub.execute_input":"2025-03-25T05:35:10.068339Z","iopub.status.idle":"2025-03-25T05:35:11.324206Z","shell.execute_reply.started":"2025-03-25T05:35:10.068312Z","shell.execute_reply":"2025-03-25T05:35:11.323210Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 2.99%\n","output_type":"stream"}],"execution_count":20}]}