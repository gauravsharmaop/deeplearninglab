{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11133476,"sourceType":"datasetVersion","datasetId":6943859}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:55:35.671822Z","iopub.execute_input":"2025-03-23T09:55:35.672304Z","iopub.status.idle":"2025-03-23T09:55:35.987131Z","shell.execute_reply.started":"2025-03-23T09:55:35.672256Z","shell.execute_reply":"2025-03-23T09:55:35.986442Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/poems100/poems.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom collections import defaultdict\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:55:38.822163Z","iopub.execute_input":"2025-03-23T09:55:38.822649Z","iopub.status.idle":"2025-03-23T09:55:42.302159Z","shell.execute_reply.started":"2025-03-23T09:55:38.822616Z","shell.execute_reply":"2025-03-23T09:55:42.301468Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load dataset from CSV\ndef load_data(csv_path):\n    df = pd.read_csv(csv_path)\n    text = ' '.join(df['text'].tolist())  # Assuming 'poem' column has text\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:55:45.729831Z","iopub.execute_input":"2025-03-23T09:55:45.730262Z","iopub.status.idle":"2025-03-23T09:55:45.735967Z","shell.execute_reply.started":"2025-03-23T09:55:45.730237Z","shell.execute_reply":"2025-03-23T09:55:45.734657Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# # load data is returning a single string\n# text = load_data('/kaggle/input/poems100/poems.csv')\n\n# print(text[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(text):\n    words = text.split()\n    vocab = sorted(set(words))\n    word_to_idx = {word: i for i, word in enumerate(vocab)}\n    idx_to_word = {i: word for word, i in word_to_idx.items()}\n    return words, vocab, word_to_idx, idx_to_word\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:55:52.025393Z","iopub.execute_input":"2025-03-23T09:55:52.025714Z","iopub.status.idle":"2025-03-23T09:55:52.030253Z","shell.execute_reply.started":"2025-03-23T09:55:52.025681Z","shell.execute_reply":"2025-03-23T09:55:52.029151Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# words, vocab, word_to_idx, idx_to_word = tokenize(text)\n\n# print(words[3])\n# print(len(words))\n# print(len(vocab))\n\n\n# word is a lsit of words , vocab is a list of unique words word_to_idx is a dictionar maps each word to an index\n# idx_to_word is a dictionar which is the reverse of word_to_idx","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_words(words, word_to_idx):\n    return torch.tensor([word_to_idx[word] for word in words], dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:55:56.225087Z","iopub.execute_input":"2025-03-23T09:55:56.225445Z","iopub.status.idle":"2025-03-23T09:55:56.229616Z","shell.execute_reply.started":"2025-03-23T09:55:56.225416Z","shell.execute_reply":"2025-03-23T09:55:56.228659Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# encoded = one_hot_encode(words,len(vocab),word_to_idx)\n\n# print(encoded[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define PyTorch Dataset class\nclass TextDataset(Dataset):\n    def __init__(self, indexed_words, seq_length):\n        self.inputs = torch.stack([indexed_words[i:i+seq_length] for i in range(len(indexed_words) - seq_length)])\n        self.targets = indexed_words[seq_length:]\n    \n    def __len__(self):\n        return len(self.inputs)\n    \n    def __getitem__(self, idx):\n        return self.inputs[idx], self.targets[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:56:00.006859Z","iopub.execute_input":"2025-03-23T09:56:00.007143Z","iopub.status.idle":"2025-03-23T09:56:00.011985Z","shell.execute_reply.started":"2025-03-23T09:56:00.007120Z","shell.execute_reply":"2025-03-23T09:56:00.011141Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define RNN model with Embedding Layer\nclass SimpleRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, dropout_rate=0.3):\n        super(SimpleRNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.rnn(x)\n        out = self.dropout(out[:, -1, :])\n        out = self.fc(out)  # No softmax; CrossEntropyLoss applies it internally\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:56:03.763413Z","iopub.execute_input":"2025-03-23T09:56:03.763736Z","iopub.status.idle":"2025-03-23T09:56:03.769193Z","shell.execute_reply.started":"2025-03-23T09:56:03.763714Z","shell.execute_reply":"2025-03-23T09:56:03.768407Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:56:07.804615Z","iopub.execute_input":"2025-03-23T09:56:07.804944Z","iopub.status.idle":"2025-03-23T09:56:07.881148Z","shell.execute_reply.started":"2025-03-23T09:56:07.804915Z","shell.execute_reply":"2025-03-23T09:56:07.880110Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Training loop\ndef train_model(model, train_loader, criterion, optimizer, epochs=25):\n    model.to(device)  # Move model to GPU\n    for epoch in range(epochs):\n        total_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n        for inputs, targets in progress_bar:\n            inputs, targets = inputs.to(device), targets.to(device).long()  # Ensure LongTensor\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            progress_bar.set_postfix(loss=total_loss/len(train_loader))\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:56:11.258886Z","iopub.execute_input":"2025-03-23T09:56:11.259172Z","iopub.status.idle":"2025-03-23T09:56:11.264617Z","shell.execute_reply.started":"2025-03-23T09:56:11.259150Z","shell.execute_reply":"2025-03-23T09:56:11.263676Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Using device: {device}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"csv_path = \"/kaggle/input/poems100/poems.csv\"  # Change this to your actual CSV file path\ntext = load_data(csv_path)\nwords, vocab, word_to_idx, idx_to_word = tokenize(text)\nindexed_words = encode_words(words, word_to_idx)\n\nseq_length = 10  # Adjusted sequence length for better training\nbatch_size = 32  # Increased batch size to fully utilize T4 GPU\n\ndataset = TextDataset(indexed_words, seq_length)\ntrain_size = int(0.9 * len(dataset))  # Increased training split\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\ndataloader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\ndataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:56:16.206396Z","iopub.execute_input":"2025-03-23T09:56:16.206720Z","iopub.status.idle":"2025-03-23T09:56:16.379624Z","shell.execute_reply.started":"2025-03-23T09:56:16.206692Z","shell.execute_reply":"2025-03-23T09:56:16.378973Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"input_size = len(vocab)\nembedding_dim = 128  # Embedding size\nhidden_size = 256  # Increased hidden size for better learning\noutput_size = len(vocab)\n\ndropout_rate = 0.3  # Dropout to reduce overfitting\nmodel = SimpleRNN(input_size, embedding_dim, hidden_size, output_size, dropout_rate).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)  # Added L2 regularization\ntrain_model(model, dataloader_train, criterion, optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:56:19.523506Z","iopub.execute_input":"2025-03-23T09:56:19.523799Z","iopub.status.idle":"2025-03-23T09:57:48.922773Z","shell.execute_reply.started":"2025-03-23T09:56:19.523775Z","shell.execute_reply":"2025-03-23T09:57:48.921683Z"}},"outputs":[{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 7.4868393088209215\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 6.75057561301637\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 6.25886596824931\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 5.734122224237727\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 5.174198654876358\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 4.628596933751271\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 4.08146356029072\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 3.5510653473179916\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 3.0783723044669493\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19, Loss: 0.6727391767861515\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20, Loss: 0.5765424614622333\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21, Loss: 0.4924088331560294\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22, Loss: 0.42885800671560326\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23, Loss: 0.37430697906462623\n","output_type":"stream"},{"name":"stderr","text":"                                                                         \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24, Loss: 0.3318963312468995\n","output_type":"stream"},{"name":"stderr","text":"                                                                         ","output_type":"stream"},{"name":"stdout","text":"Epoch 25, Loss: 0.2857505098499101\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Test loop for accuracy\ndef test_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(device), targets.to(device).long()  # Ensure LongTensor\n            outputs = model(inputs)\n            predicted = torch.argmax(outputs, dim=1)\n            correct += (predicted == targets).sum().item()\n            total += targets.size(0)\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:01:38.790941Z","iopub.execute_input":"2025-03-23T10:01:38.791271Z","iopub.status.idle":"2025-03-23T10:01:38.796518Z","shell.execute_reply.started":"2025-03-23T10:01:38.791245Z","shell.execute_reply":"2025-03-23T10:01:38.795810Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"test_model(model, dataloader_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:01:43.163087Z","iopub.execute_input":"2025-03-23T10:01:43.163473Z","iopub.status.idle":"2025-03-23T10:01:43.423830Z","shell.execute_reply.started":"2025-03-23T10:01:43.163443Z","shell.execute_reply":"2025-03-23T10:01:43.422891Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 6.96%\n","output_type":"stream"}],"execution_count":13}]}